{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watsonx import WatsonxAI\n",
    "import warnings\n",
    "from colorama import Fore, Back\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "\n",
    "load_dotenv()\n",
    "BRAVE_API_KEY = getenv(\"BRAVE_API_KEY\", None)\n",
    "\n",
    "\n",
    "proxy = \"proxy.us.ibm.com:8080\"\n",
    "\n",
    "wx = WatsonxAI()\n",
    "wx.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"strawberry\" contains one 'r'.\n"
     ]
    }
   ],
   "source": [
    "def gen_naive_answer(question):\n",
    "    \"\"\"\n",
    "    get the AI answer the question directly.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"<|user|>\n",
    "please answer the question.\n",
    "<<SYS>>\n",
    "question: `{question}`\n",
    "<</SYS>>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "answer = gen_naive_answer(\"how many r in strawberry?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_review(draft):\n",
    "    prompt = f\"\"\"<|user|>\n",
    "please review the draft provided.\n",
    "-check if any illogical content.\n",
    "-check if any unclear content.\n",
    "-give contructive suggestion.\n",
    "draft: `{draft}`\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "def gen_revise(content,review):\n",
    "    prompt = f\"\"\"<|user|>\n",
    "please revise the content base on the review provided.\n",
    "-well adopt the suggestion provided.\n",
    "-generate the revised content only.\n",
    "content: `{content}`\n",
    "review: `{review}`\n",
    "<|assistant|>\n",
    "revised version:\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "requirement = \"plan a trip to jakarta for 3 days\"\n",
    "\n",
    "draft = gen_naive_answer(requirement)\n",
    "print(\"draft:\")\n",
    "print(Fore.BLUE, draft)\n",
    "\n",
    "review = gen_review(draft)\n",
    "print(\"review:\")\n",
    "print(Fore.RED, review)\n",
    "\n",
    "revise = gen_revise(draft,review)\n",
    "print(\"revise:\")\n",
    "print(Fore.YELLOW, revise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 1: Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_thought(requirement):\n",
    "    \"\"\"\n",
    "    get the AI not jump to conclusion or action, try approach a problem with thought first.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"<|system|>\n",
    "you are a chatbot that answer general question.\n",
    "-understand the requirement in detail.\n",
    "-list out what knowlege you need to answer the requirement.\n",
    "-take the simplest solution.\n",
    "-classify what domain this requirement about.\n",
    "-think about where will the right source of the answer.\n",
    "-think logically.\n",
    "-think step by step.\n",
    "-you trust the result of the tools more than your memory.\n",
    "-you trust the knowledge provide more than your memory.\n",
    "-leverage tool if possible.\n",
    "-dont guess.\n",
    "-dont overcomplicate.\n",
    "-declare the assumption you made.\n",
    "-NEVER generate Final Result\n",
    "<|user|>\n",
    "please generate your thought on the question provided.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "<</SYS>>\n",
    "<|assistant|>\n",
    "thought:\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "requirement = \"how many r in strawberry?\"\n",
    "thought = gen_thought(requirement)\n",
    "print(thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_plan(requirement):\n",
    "    \"\"\"\n",
    "    get the API to break down the big task to smaller sub-tasks. that easier to execute\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"<|system|>\n",
    "-dont overcomplicate.\n",
    "-think logically.\n",
    "-think step by step.\n",
    "-dont guess.\n",
    "-you trust the result of the tools more than your memory.\n",
    "-you trust the knowledge provide more than your memory.\n",
    "-you trust the status provided. no need to check on it.\n",
    "<|user|>\n",
    "please generate a concise and solid plan to satisfy the requirement provided.\n",
    "-understand the requirement in detail.\n",
    "-understand the requirement with common sense.\n",
    "-understand the status provided.\n",
    "-list out what knowlege you need to satisfy the requirement.\n",
    "-leverage tool if possible.\n",
    "-please breakdown complex task to simple tasks.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "<</SYS>>\n",
    "-DONT generate result of the steps.\n",
    "-DONT generate status.\n",
    "-**DONT** generate **Final Result:**\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "def gen_next_step(plan,status):\n",
    "    \"\"\"\n",
    "    get the API to break down the big task to smaller sub-tasks. that easier to execute\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"<|system|>\n",
    "<|user|>\n",
    "please check the status against the plan provided.\n",
    "-understand the plan provided in detail.\n",
    "-understand the status provided in detail.\n",
    "-generate next step base on status if has next step.\n",
    "-print 'complete' if no next step.\n",
    "<<SYS>>\n",
    "plan: `{plan}`\n",
    "status: `{status}`\n",
    "output format: {{\n",
    "    next_step:,\n",
    "    complete: yes/no,\n",
    "}}\n",
    "<</SYS>>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return answer\n",
    "\n",
    "plan = gen_plan(\"goto Jakarta from Singapore\")\n",
    "print(\"plan:\")\n",
    "print(plan)\n",
    "\n",
    "next_step = gen_next_step(plan,\"I have the visa and passport\")\n",
    "print(\"next step:\")\n",
    "print(next_step)\n",
    "\n",
    "next_step = gen_next_step(plan,\"already in Jakarta\")\n",
    "print(\"next step:\")\n",
    "print(next_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern 3: Use Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import ast\n",
    "import json\n",
    "\n",
    "def get_function_signature_and_docstring(func):\n",
    "    source_lines = inspect.getsourcelines(func)[0]\n",
    "    source = ''.join(source_lines)\n",
    "\n",
    "    # Parse the function definition using AST (Abstract Syntax Trees)\n",
    "    parsed_func = ast.parse(source)\n",
    "\n",
    "    # Extract function signature and docstring\n",
    "    func_signature = ''\n",
    "    docstring = ''\n",
    "    return_type = ''\n",
    "    for node in parsed_func.body:\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            func_signature = source_lines[node.lineno - 1].strip()\n",
    "            docstring = ast.get_docstring(node) or ''\n",
    "            # Get return type annotation\n",
    "            return_type = node.returns.id if node.returns else 'None'\n",
    "            break\n",
    "\n",
    "    return func_signature, docstring, return_type\n",
    "\n",
    "def format_function_info(func):\n",
    "    func_signature, docstring, return_type = get_function_signature_and_docstring(func)\n",
    "    function_name = func.__name__\n",
    "\n",
    "    # Extract parameters from a JSON schema-like structure\n",
    "    parameters = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {}\n",
    "    }\n",
    "\n",
    "    # Get the function's parameters and their annotations\n",
    "    func_params = inspect.signature(func).parameters\n",
    "    for param_name, param in func_params.items():\n",
    "        param_type = param.annotation\n",
    "        param_description = \"\"  # You can add a description here if needed\n",
    "        parameters[\"properties\"][param_name] = {\n",
    "            \"type\": str(param_type),\n",
    "            \"description\": param_description\n",
    "        }\n",
    "\n",
    "    # Set the required parameters based on function annotations\n",
    "    required_params = [param_name for param_name, param in func_params.items() if param.default == inspect.Parameter.empty]\n",
    "    parameters[\"required\"] = required_params\n",
    "\n",
    "    return {\n",
    "        \"name\": function_name,\n",
    "        \"parameters\": parameters,\n",
    "        \"description\": docstring,\n",
    "        \"return_type\": return_type\n",
    "    }\n",
    "\n",
    "def get_tools_prompt(tools):\n",
    "    prompt = \"[\"\n",
    "    # Get the source code of the function\n",
    "    for tool in tools:\n",
    "        info = format_function_info(tool)\n",
    "        prompt = prompt + f\"{info}\\n\"\n",
    "    prompt = prompt + \"]\"\n",
    "    return prompt\n",
    "\n",
    "def pick_tool(job,thought,tools):\n",
    "    \"\"\"\n",
    "    pick a tool from toolbox, that best match the need for requirement.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"<|system|>\n",
    "You are a helpful assistant with access to the following function calls. \n",
    "- Your task is to produce a sequence of function calls necessary to generate response to the user utterance. \n",
    "- well understand the thought to articulate the task.\n",
    "- well understand the description and parameters of tools.\n",
    "= select appropriate parameter for the tool.\n",
    "- only pick the function required and provided in tools.\n",
    "- show \"missing tool\" if no appropriate function provided.\n",
    "- DONT explain.\n",
    "output format: [{{\"name\": \"function\", \"arguments\": {{\"arg\": \"value\"}}}}]\n",
    "<<TOOLS>>\n",
    "{get_tools_prompt(tools)}\n",
    "<</TOOLS>>\n",
    "<|user|>\n",
    "thought: `{thought}`\n",
    "job: `{job}`\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    # print(prompt)\n",
    "    # print(\">>\"+step)\n",
    "    tool = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT)\n",
    "    return tool\n",
    "\n",
    "def use_tool(func_json_str):\n",
    "    \"\"\"\n",
    "    you already hv the tool, let run it.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the JSON string into Python objects\n",
    "        function_calls = json.loads(func_json_str)\n",
    "        \n",
    "        # Dictionary to store results\n",
    "        results = {}\n",
    "        \n",
    "        # Iterate over each function call in the list\n",
    "        for call in function_calls:\n",
    "            func_name = call.get(\"name\")\n",
    "            args = call.get(\"arguments\", {})\n",
    "            print(f\"calling {func_name}({args})...\")\n",
    "            \n",
    "            # Check if the function exists in the global namespace\n",
    "            if func_name in globals() and callable(globals()[func_name]):\n",
    "                try:\n",
    "                    # Retrieve the function object\n",
    "                    func = globals()[func_name]\n",
    "                    \n",
    "                    # Call the function with the provided arguments\n",
    "                    result = func(**args)\n",
    "                    \n",
    "                    # Store the result\n",
    "                    results[f\"{func_name}({args})\"] = result\n",
    "                except Exception as e:\n",
    "                    # Handle exceptions raised by the function\n",
    "                    results[f\"{func_name}({args})\"] = f\"Error executing {func_name}: {str(e)}\"\n",
    "            else:\n",
    "                # Function not found or not callable\n",
    "                results[f\"{func_name}({args})\"] = f\"Function '{func_name}' not found or is not callable.\"\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except json.JSONDecodeError as jde:\n",
    "        return {\"JSONDecodeError\": f\"Invalid JSON input: {str(jde)}\"}\n",
    "    except Exception as ex:\n",
    "        return {\"Error\": f\"An unexpected error occurred: {str(ex)}\"}\n",
    "    \n",
    "def gen_summary_from_knowledge(question,knowledge):\n",
    "    prompt = f\"\"\"<|user|>\n",
    "help answer the question provided base on the knowledge provided.\n",
    "-focus on what you found instead of not found.\n",
    "-if no answer provide, just say you dont know.\n",
    "<<SYS>>\n",
    "question = `{question}`\n",
    "knowledge = `{knowledge}`\n",
    "<</SYS>>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT,8000)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import wikipediaapi\n",
    "import requests\n",
    "import yfinance as yf\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "\n",
    "load_dotenv()\n",
    "PROXY = getenv(\"PROXY\", None)\n",
    "\n",
    "def query_wikipedia(topic)->str:\n",
    "    \"\"\"\n",
    "    only use it for ONE keyword/topic. \n",
    "    NEVER applicable to long query.\n",
    "    get detail definition and information of particular topic\n",
    "    only ONE keyword/topic will be support. please use appropriate one.\n",
    "    only support very specific short keyword or topic.\n",
    "\n",
    "    Parameters:\n",
    "    topic (str): The ONE keyword/topic for which the information is required.\n",
    "\n",
    "    Returns:\n",
    "    str: A dictionary containing the title, summary, and URL of the Wikipedia page for the given topic. If the page is not found, it returns \"Page not found.\"\n",
    "    \"\"\"\n",
    "    wiki = wikipediaapi.Wikipedia('watsonx',proxies={'http': PROXY,'https':PROXY})\n",
    "    page = wiki.page(topic)\n",
    "\n",
    "    if page.exists():\n",
    "        return {\n",
    "            \"title\": page.title,\n",
    "            \"summary\": page.summary,\n",
    "            \"url\": page.fullurl\n",
    "        }\n",
    "    else:\n",
    "        return \"Page not found.\"\n",
    "\n",
    "def get_stock_data(ticker, period='5d', interval='1d')->str:\n",
    "    \"\"\"\n",
    "    get stock price. it is for stock data only.\n",
    "    the input is ticker (should be a stock code)\n",
    "    dont put other thing to ticker.\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "    session.proxies = {\n",
    "        'http': PROXY,\n",
    "        'https': PROXY\n",
    "    }\n",
    "\n",
    "    stock = yf.Ticker(ticker, session=session)\n",
    "    data = stock.history(period=period, interval=interval)\n",
    "    return data\n",
    "\n",
    "def get_current_time(location)->str:\n",
    "    \"\"\"\n",
    "    Get the current time by location.\n",
    "\n",
    "    Args:\n",
    "        location (str) need to be in format of 'Europe/London'\n",
    "\n",
    "    Returns:\n",
    "        str: The current time in the specified location.\n",
    "\n",
    "    Example:\n",
    "        get_current_time('Europe/London')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        location_time = datetime.now(pytz.timezone(location))\n",
    "        return location_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "tools = [query_wikipedia,get_stock_data,get_current_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agentic_from_tool(question,tools,debug=False):\n",
    "    # print(get_tools_prompt(tools))\n",
    "    # thought = gen_thought(question)\n",
    "    action = pick_tool(question,\"\",tools)\n",
    "    if debug:\n",
    "        print(f\"action:{action}\")\n",
    "    answer = use_tool(action)\n",
    "    if debug:\n",
    "        print(f\"tool result:{answer}\")\n",
    "    summary = gen_summary_from_knowledge(question,answer)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive:\n",
      "The Mariana Trench, located in the western Pacific Ocean, is approximately 36,070 feet (10,994 meters) deep at its deepest point, known as the Challenger Deep. This makes it the deepest part of the world's oceans.\n",
      "use tool:\n",
      "calling query_wikipedia({'topic': 'Mariana Trench'})...\n",
      "The Mariana Trench, located in the western Pacific Ocean, is the deepest oceanic trench on Earth. Its maximum known depth is 10,984 ± 25 meters (36,037 ± 82 feet; 6,006 ± 14 fathoms; 6.825 ± 0.016 miles). This depth is more than 2 kilometers (1.2 miles) farther from sea level than the peak of Mount Everest. The pressure at the bottom of the trench is 1,086 bar (15,750 psi), and the temperature ranges from 1 to 4 degrees Celsius (34 to 39 degrees Fahrenheit). One-celled organisms called monothalamea have been found at a record depth of 10.6 kilometers (35,000 feet; 6.6 miles) below the sea surface.\n"
     ]
    }
   ],
   "source": [
    "answer = gen_naive_answer(\"how deep is Mariana Trench\")\n",
    "print(\"naive:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"use tool:\")\n",
    "answer = run_agentic_from_tool(\"how deep is Mariana Trench\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive:\n",
      "As of my last update, I don't have real-time data or the ability to browse the internet. However, I can guide you on how to find the latest stock price of IBM. You can check financial websites like Yahoo Finance, Google Finance, or Bloomberg for the most recent stock prices. Please ensure you're using a reliable source and that the information is up-to-date.\n",
      "use tool:\n",
      "calling get_stock_data({'ticker': 'IBM'})...\n",
      "Based on the provided knowledge, the latest stock price of IBM as of November 18, 2024, was $208.089996. This is the closing price for that day. The volume of shares traded on that day was 2658508. There were no dividends or stock splits reported for this period.\n"
     ]
    }
   ],
   "source": [
    "answer = gen_naive_answer(\"analysis the latest stock price of IBM\")\n",
    "print(\"naive:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"use tool:\")\n",
    "answer = run_agentic_from_tool(\"analysis the latest stock price of IBM\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive:\n",
      "The current time in Sydney, Australia is [insert current time here]. Please note that Sydney observes Daylight Saving Time from early October to early April, during which the time zone is UTC+10:30. The rest of the year, it follows UTC+11:00.\n",
      "use tool:\n",
      "calling get_current_time({'location': 'Australia/Sydney'})...\n",
      "The current time in Sydney is 13:36:25 on November 19, 2024.\n"
     ]
    }
   ],
   "source": [
    "answer = gen_naive_answer(\"when it is now in Sydney\")\n",
    "print(\"naive:\")\n",
    "print(answer)\n",
    "\n",
    "print(\"use tool:\")\n",
    "answer = run_agentic_from_tool(\"when it is now in Sydney\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wx.connect()\n",
    "\n",
    "# answer = query_wikipedia(\"olympics\")\n",
    "# # print(answer)\n",
    "\n",
    "# answer = gen_naive_answer( \"who win the 47th president of USA\")\n",
    "# print(answer)\n",
    "\n",
    "# answer = gen_answer_from_knowledge(\"who win the 47th president of USA\",tools,debug=True)\n",
    "# print(answer)\n",
    "\n",
    "answer = run_agentic_from_tool(\"who win the 47th president of USA\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = gen_naive_answer( \"when it is now in hong kong\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"how many hour different of hong kong to SFO\",tools)\n",
    "print(answer)\n",
    "\n",
    "answer = run_agentic_from_tool(\"how many hour different of hong kong to SFO\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = gen_naive_answer(\"compare UK and france\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"compare UK and france\",tools)\n",
    "print(answer)\n",
    "\n",
    "answer = run_agentic_from_tool(\"compare UK and france\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = gen_naive_answer(\"compare IBM and AMAZON stock price today\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"compare IBM and AMAZON stock price today\",tools)\n",
    "print(answer)\n",
    "\n",
    "answer = run_agentic_from_tool(\"compare IBM and AMAZON stock price today\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agentic_from_tool(\"who is competitor of vllm\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = run_agentic_from_tool(\"will it be typhoon tmr in hong kong\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = gen_answer_from_knowledge(\"stock price of IBM compare to MSFT\",tools)\n",
    "print(answer)\n",
    "\n",
    "answer = run_agentic_from_tool(\"stock price of IBM compare to MSFT\",tools)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = gen_answer_from_knowledge(\"compare Mickey Mouse and Indiana Jones\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"compare Trump and Biden\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"tell me about star war\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"tell me about beijing and paris on olympics\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"tell me about TVB\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"stock price of IBM\")\n",
    "print(answer)\n",
    "\n",
    "answer = gen_answer_from_knowledge(\"what is official language of singapore\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) solve problem by coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "def gen_code(requirement,code,plan,error,tools,debug=False):\n",
    "    prompt = f\"\"\"<|user|>\n",
    "please generate python code that execute the plan to fulfill the requirement.\n",
    "-understand the requriement in detail.\n",
    "-understand the tool provided.\n",
    "-ensure the python generated is executable.\n",
    "-clean up if any unneccessary characters.\n",
    "-review the problem in the code and the error if provided.\n",
    "-prevent the error from the code if provided.\n",
    "-involve the tool provided directly without define it.\n",
    "-understand the plan in detail. dont miss the steps.\n",
    "-**DONT** use SaaS service which need API KEY.\n",
    "-**DONT** catch error.\n",
    "-raise error when hit problem.\n",
    "-**DONT** request input.\n",
    "-**DONT** throw SystemExit\n",
    "-**DONT** generate main().\n",
    "-**DONT** generate explanation.\n",
    "-ensure print the answer to output explicitely.\n",
    "-generate the code directly.\n",
    "-generate the code only.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "code with problem: `{code}`\n",
    "plan: `{plan}`\n",
    "error: `{error}`\n",
    "-involve the tool provided directly without define it.\n",
    "tools: `{get_tools_prompt(tools)}`\n",
    "<</SYS>>\n",
    "-dont generate explanation.\n",
    "-dont generate note.\n",
    "-generate the code directly only.\n",
    "<|assistant|>\n",
    "```python\"\"\"\n",
    "    if debug:\n",
    "        print(prompt)\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT).replace(\"```\",\"\")\n",
    "    return answer\n",
    "\n",
    "def create_local_namespace(tools):\n",
    "    return {func.__name__: func for func in tools}\n",
    "\n",
    "def run_code(module_import, function_call, tools, max_traceback_lines=5):\n",
    "    \"\"\"\n",
    "    try to run the generated code to get the answer.\n",
    "    \"\"\"\n",
    "    # Create StringIO objects to capture standard output and error output\n",
    "    output_stream = io.StringIO()\n",
    "    error_stream = io.StringIO()\n",
    "\n",
    "    # Redirect stdout and stderr\n",
    "    old_stdout = sys.stdout\n",
    "    old_stderr = sys.stderr\n",
    "    sys.stdout = output_stream\n",
    "    sys.stderr = error_stream\n",
    "\n",
    "    output = None\n",
    "    error = None\n",
    "\n",
    "    # Using exec to import the module and evaluate the function call\n",
    "    try:\n",
    "        local_namespace = create_local_namespace(tools)\n",
    "        exec(module_import, local_namespace, local_namespace)  # Dynamically import the module\n",
    "        # print(f\"|{function_call}|\")\n",
    "        exec(function_call, local_namespace, local_namespace)  # Evaluate the function call\n",
    "    except ImportError as e:\n",
    "        error = f\"Import Error: {str(e)}\"\n",
    "    except Exception as e:\n",
    "        # Capture the traceback for more detailed error information\n",
    "        full_traceback = traceback.format_exc().strip()\n",
    "        # Limit the traceback to the last 'max_traceback_lines' lines\n",
    "        limited_traceback = \"\\n\".join(full_traceback.splitlines()[-max_traceback_lines:])\n",
    "        error = f\"Unexpected Error: {str(e)}\\n{limited_traceback}\"\n",
    "    finally:\n",
    "        # Reset stdout to its original state\n",
    "        sys.stdout = old_stdout\n",
    "        sys.stderr = old_stderr\n",
    "\n",
    "    # Get the output from the output_stream\n",
    "    output = output_stream.getvalue().strip()\n",
    "    error_output = error_stream.getvalue().strip()\n",
    "\n",
    "    # Check the output or error\n",
    "    if error:\n",
    "        return f\"Output: {output}\", f\"Error: {error}\"\n",
    "    elif error_output:\n",
    "        return f\"Output: {output}\", f\"Error Output: {error_output}\"\n",
    "    else:\n",
    "        return f\"Output: {output}\", None\n",
    "    \n",
    "def gen_eval(question,stdout):\n",
    "    prompt = f\"\"\"<|user|>classify if stdout include error.\n",
    "-show sucess or fail only, but nothing else.\n",
    "-show success if include no error. and end the generation.\n",
    "-show fail if include error. and end the generation.\n",
    "<<SYS>>\n",
    "question: `{question}`\n",
    "stdout: `{stdout}`\n",
    "<</SYS>>\n",
    "<|assistant|>success or fail:\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT).replace(\"```\",\"\")\n",
    "    return answer\n",
    "    \n",
    "def gen_code_summary(requirement,code,output):\n",
    "    prompt= f\"\"\"<|user|>\n",
    "please generate a complete sentence summary base on the answer provided only.\n",
    "-dont use your common sense.\n",
    "-declare the assumption you made.\n",
    "-only base on the requirement and answer provided.\n",
    "-the output comes from the code execution.\n",
    "-dont guess.\n",
    "<<SYS>>\n",
    "requirement: `{requirement}`\n",
    "code: `{code}`\n",
    "answer: `{output}`\n",
    "-dont mention about code.\n",
    "-use simple english.\n",
    "<</SYS>>\n",
    "<|assistant|>answer summary:\"\"\"\n",
    "    answer = wx.watsonx_gen(prompt,wx.GRANITE_3_8B_INSTRUCT).replace(\"```\",\"\").replace(\"<|user|>\",\"\")\n",
    "    return answer\n",
    "\n",
    "def run_agentic_with_coding(requirement, max_turns=10, debug=False):\n",
    "    \"\"\"\n",
    "    gen thought or plan first.\n",
    "    for each turns:\n",
    "        gen code base on plan until output is error free\n",
    "    gen summary\n",
    "    \"\"\"\n",
    "    thought = gen_thought(requirement)\n",
    "    if debug:\n",
    "        print(f\"thought: {thought}\")\n",
    "\n",
    "    plan = thought\n",
    "\n",
    "    code = \"\"\n",
    "    error = \"\"\n",
    "    # Loop until the review output is empty\n",
    "    for turn in range(max_turns):\n",
    "        print(f\"turn #{turn+1} ---\")\n",
    "        # output = exec_with_output(code)\n",
    "        code = gen_code(requirement, code , plan, error, tools)\n",
    "        if debug:\n",
    "            print(f\"code: {code}\")\n",
    "        output, error = run_code(\"\",code, tools)\n",
    "        if debug:\n",
    "            print(f\"output: {output}\")\n",
    "        \n",
    "        if error is None:\n",
    "            break\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f\"error {error}\")\n",
    "        # review = eval_output(requirement, output)\n",
    "        # if debug:\n",
    "        #     print(f\"#4: {review}\")\n",
    "        \n",
    "        # if \"success\" in review:  # Exit if review output is empty\n",
    "        #     # print(f\"#final result: {output}\")\n",
    "        #     break\n",
    "\n",
    "    summary = gen_code_summary(requirement, code, output)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run_agentic_with_coding(\"tell me is it only 100 prime number with in 10000?\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me is it only 100 prime number with in 1000?\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me all prime number with in 1000?\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me all prime number with in 1000? and it need to be ends with 7\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many prime number with in 10000\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many R in straberry\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many r in straberry\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many r/R in straberry\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many 'a' in canada\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many A in 'canada', dont check case\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"how many a or A in the word canada\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"in math, compare 9.11 with 9.8\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"9.1 9.11 and 9.21, 9.8, which is bigger? and which is smaller\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"compare 9.11 with 9.8\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"which of 9.11 9.8 is bigger\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"compare 9.11 with 9.A\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me Korea time\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me how is the different of Korea time and Hong Kong time\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me Hong Kong time\")\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"search Hong Kong on wiki\",debug=True)\n",
    "print(output)\n",
    "\n",
    "output = run_agentic_with_coding(\"tell me about Paris\",debug=True)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
